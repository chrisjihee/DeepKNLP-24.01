/raid/chrisjihee/miniforge3/envs/DeepKNLP-24.01/bin/python /raid/chrisjihee/proj/DeepKNLP-24.01/1-doc-cls-fab.py 
[03.15 15:59:53] ┇ INFO     ┇          lightning.fabric.utilities.seed ┇ Seed set to 7
[03.15 15:59:53] ┇ INFO     ┇                           chrisbase.data ┇ =========================================================================================================================================
[03.15 15:59:53] ┇ INFO     ┇                           chrisbase.data ┇ [INIT] python /raid/chrisjihee/proj/DeepKNLP-24.01/1-doc-cls-fab.py 
[03.15 15:59:53] ┇ INFO     ┇                           chrisbase.data ┇ =========================================================================================================================================
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇ -----+---------------------------------+-------------------------------------------------------------------------------------
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇    # | TrainerArguments                | value
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇ -----+---------------------------------+-------------------------------------------------------------------------------------
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇    1 | tag                             | train
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇    2 | env.project                     | DeepKNLP
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇    3 | env.job_name                    | KPF-BERT
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇    4 | env.hostname                    | dgx-a100
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇    5 | env.hostaddr                    | 129.254.23.12
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇    6 | env.python_path                 | /raid/chrisjihee/miniforge3/envs/DeepKNLP-24.01/bin/python
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇    7 | env.current_dir                 | /raid/chrisjihee/proj/DeepKNLP-24.01
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇    8 | env.current_file                | /raid/chrisjihee/proj/DeepKNLP-24.01/1-doc-cls-fab.py
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇    9 | env.working_dir                 | /raid/chrisjihee/proj/DeepKNLP-24.01
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   10 | env.command_args                | []
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   11 | env.num_ip_addrs                | 1
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   12 | env.max_workers                 | 1
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   13 | env.output_home                 | /raid/chrisjihee/proj/DeepKNLP-24.01/finetuning/nsmc/train=KPF-BERT/0315.155950
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   14 | env.logging_file                |
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   15 | env.argument_file               | train-arguments-0315.155950-train.json
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   16 | env.debugging                   | False
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   17 | env.msg_level                   | 20
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   18 | env.msg_format                  | %(asctime)s ┇ %(levelname)-8s ┇ %(name)40s ┇ %(message)s
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   19 | env.date_format                 | [%m.%d %H:%M:%S]
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   20 | env.time_stamp                  | 0315.155950
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   21 | time.started                    | [03.15 15:59:54]
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   22 | time.settled                    |
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   23 | time.elapsed                    |
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   24 | prog.result                     | {}
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   25 | prog.tb_logger                  | <lightning.fabric.loggers.tensorboard.TensorBoardLogger object at 0x7f51df149510>
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   26 | prog.csv_logger                 | <lightning.fabric.loggers.csv_logs.CSVLogger object at 0x7f50743d1810>
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   27 | prog.world_size                 | 1
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   28 | prog.node_rank                  | 0
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   29 | prog.local_rank                 | 0
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   30 | prog.global_rank                | 0
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   31 | prog.global_step                | 0
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   32 | prog.global_epoch               | 0.0
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   33 | data.name                       | nsmc
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   34 | data.home                       | /raid/chrisjihee/proj/DeepKNLP-24.01/data
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   35 | data.files                      | {'train': 'ratings_train.txt', 'valid': 'ratings_test.txt', 'test': None}
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   36 | data.caching                    | False
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   37 | data.redownload                 | False
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   38 | data.num_check                  | 2
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   39 | data.num_entity                 |
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   40 | data.num_relation               |
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   41 | model.pretrained                | pretrained/KPF-BERT
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   42 | model.finetuning                | /raid/chrisjihee/proj/DeepKNLP-24.01/finetuning
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   43 | model.seq_len                   | 64
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   44 | model.config                    |
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   45 | model.name                      |
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   46 | model.src_max_length            | 512
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   47 | model.train_tgt_max_length      | 512
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   48 | model.eval_tgt_max_length       | 90
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   49 | model.src_descrip_max_length    | 0
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   50 | model.tgt_descrip_max_length    | 0
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   51 | model.seq_dropout               | 0.1
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   52 | model.decoder                   | beam_search
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   53 | model.num_beams                 | 40
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   54 | model.num_beam_groups           | 1
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   55 | model.diversity_penalty         | 0.0
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   56 | model.use_prefix_search         | False
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   57 | hardware.cpu_workers            | 256
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   58 | hardware.train_batch            | 64
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   59 | hardware.infer_batch            | 64
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   60 | hardware.accelerator            | gpu
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   61 | hardware.precision              | 32-true
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   62 | hardware.strategy               | auto
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   63 | hardware.devices                | [1]
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   64 | learning.random_seed            | 7
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   65 | learning.optimizer_cls          | Adam
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   66 | learning.learning_rate          | 5e-05
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   67 | learning.saving_mode            | max val_acc
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   68 | learning.num_saving             | 3
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   69 | learning.num_epochs             | 3
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   70 | learning.log_text               | False
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   71 | learning.check_rate_on_training | 0.1
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   72 | learning.print_rate_on_training | 0.03333333333333333
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   73 | learning.print_rate_on_validate | 0.3333333333333333
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   74 | learning.print_rate_on_evaluate | 0.3333333333333333
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   75 | learning.print_step_on_training | -1
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   76 | learning.print_step_on_validate | -1
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   77 | learning.print_step_on_evaluate | -1
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   78 | learning.tag_format_on_training | st={step:d}, ep={epoch:.2f}, loss={loss:06.4f}, acc={acc:06.4f}
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   79 | learning.tag_format_on_validate | st={step:d}, ep={epoch:.2f}, val_loss={val_loss:06.4f}, val_acc={val_acc:06.4f}
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   80 | learning.tag_format_on_evaluate | st={step:d}, ep={epoch:.2f}, test_loss={test_loss:06.4f}, test_acc={test_acc:06.4f}
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇   81 | learning.name_format_on_saving  | ep={epoch:.1f}, loss={val_loss:06.4f}, acc={val_acc:06.4f}
[03.15 15:59:54] ┇ INFO     ┇                           chrisbase.data ┇ -----+---------------------------------+-------------------------------------------------------------------------------------
[03.15 15:59:54] ┇ WARNING  ┇              transformers.modeling_utils ┇ Some weights of BertForSequenceClassification were not initialized from the model checkpoint at pretrained/KPF-BERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[03.15 15:59:58] ┇ INFO     ┇                                 __main__ ┇ === [after-model] =======================================================================================================================
[03.15 15:59:58] ┇ INFO     ┇                       nlpbook.cls.corpus ┇ Creating features from /raid/chrisjihee/proj/DeepKNLP-24.01/data/nsmc/ratings_train.txt
[03.15 15:59:59] ┇ INFO     ┇                       nlpbook.cls.corpus ┇ Loaded 150000 examples from /raid/chrisjihee/proj/DeepKNLP-24.01/data/nsmc/ratings_train.txt
[03.15 16:00:09] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   === [Example 1] ===
[03.15 16:00:09] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = sentence : 아 더빙.. 진짜 짜증나네요 목소리
[03.15 16:00:09] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = tokens   : [CLS] 아 더 ##빙 . . 진짜 짜증 ##나 ##네 ##요 목소리 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
[03.15 16:00:09] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = label    : 0
[03.15 16:00:09] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = features : ClassificationFeatures(input_ids=[2, 3579, 2914, 5236, 518, 518, 7496, 13611, 4773, 5142, 4672, 7484, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)
[03.15 16:00:09] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   === 
[03.15 16:00:09] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   === [Example 2] ===
[03.15 16:00:09] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = sentence : 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나
[03.15 16:00:09] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = tokens   : [CLS] 흠 . . . 포스터 ##보 ##고 초 ##딩 ##영화 ##줄 . . . . 오버 ##연 ##기 ##조 ##차 가볍 ##지 않 ##구나 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
[03.15 16:00:09] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = label    : 1
[03.15 16:00:09] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = features : ClassificationFeatures(input_ids=[2, 4326, 518, 518, 518, 15104, 4557, 4658, 3947, 5051, 20088, 5202, 518, 518, 518, 518, 13422, 4855, 4655, 4872, 4966, 10181, 4760, 3583, 9507, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)
[03.15 16:00:09] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   === 
[03.15 16:00:09] ┇ INFO     ┇                       nlpbook.cls.corpus ┇ Converted 150000 raw examples to 150000 encoded examples
[03.15 16:00:09] ┇ INFO     ┇                                 __main__ ┇ Created train_dataset providing 150000 examples
[03.15 16:00:09] ┇ INFO     ┇                                 __main__ ┇ Created train_dataloader providing 2344 batches
[03.15 16:00:09] ┇ INFO     ┇                                 __main__ ┇ === [after-train_dataloader] ============================================================================================================
[03.15 16:00:09] ┇ INFO     ┇                       nlpbook.cls.corpus ┇ Creating features from /raid/chrisjihee/proj/DeepKNLP-24.01/data/nsmc/ratings_test.txt
[03.15 16:00:10] ┇ INFO     ┇                       nlpbook.cls.corpus ┇ Loaded 50000 examples from /raid/chrisjihee/proj/DeepKNLP-24.01/data/nsmc/ratings_test.txt
[03.15 16:00:13] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   === [Example 1] ===
[03.15 16:00:13] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = sentence : 굳 ㅋ
[03.15 16:00:13] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = tokens   : [CLS] 굳 ㅋ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
[03.15 16:00:13] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = label    : 1
[03.15 16:00:13] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = features : ClassificationFeatures(input_ids=[2, 2653, 956, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=1)
[03.15 16:00:13] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   === 
[03.15 16:00:13] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   === [Example 2] ===
[03.15 16:00:13] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = sentence : GDNTOPCLASSINTHECLUB
[03.15 16:00:13] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = tokens   : [CLS] GD ##NT ##O ##P ##C ##LA ##SS ##IN ##T ##H ##EC ##L ##U ##B [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]
[03.15 16:00:13] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = label    : 0
[03.15 16:00:13] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   = features : ClassificationFeatures(input_ids=[2, 35940, 29794, 4561, 4562, 4529, 21569, 33254, 15203, 4720, 4783, 10502, 4651, 4840, 4563, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], token_type_ids=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], label=0)
[03.15 16:00:13] ┇ INFO     ┇                       nlpbook.cls.corpus ┇   === 
[03.15 16:00:13] ┇ INFO     ┇                       nlpbook.cls.corpus ┇ Converted 50000 raw examples to 50000 encoded examples
[03.15 16:00:13] ┇ INFO     ┇                                 __main__ ┇ Created val_dataset providing 50000 examples
[03.15 16:00:13] ┇ INFO     ┇                                 __main__ ┇ Created val_dataloader providing 782 batches
[03.15 16:00:13] ┇ INFO     ┇                                 __main__ ┇ === [after-val_dataloader] ==============================================================================================================
[03.15 16:00:34] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.03) training:   3%|█                             | 79/2344 [00:20<01:42, 22.17x64b/s] | st=79, ep=0.03, loss=0.4257, acc=0.7656
[03.15 16:00:38] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.07) training:   7%|██                            | 157/2344 [00:24<01:38, 22.27x64b/s] | st=157, ep=0.07, loss=0.3361, acc=0.8281
[03.15 16:00:41] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.10) training:  10%|███                           | 235/2344 [00:27<01:34, 22.25x64b/s] | st=235, ep=0.10, loss=0.2184, acc=0.9062
[03.15 16:00:58] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.10) checking:  33%|██████▋             | 261/782 [00:17<00:08, 63.24x64b/s]
[03.15 16:01:02] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.10) checking:  67%|█████████████▎      | 522/782 [00:20<00:04, 64.61x64b/s]
[03.15 16:01:05] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.10) checking: 100%|████████████████████| 782/782 [00:23<00:00, 79.40x64b/s] | st=235, ep=0.10, val_loss=0.3097, val_acc=0.8769
[03.15 16:01:08] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:01:12] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.13) training:  13%|████                          | 313/2344 [00:58<01:32, 22.02x64b/s] | st=313, ep=0.13, loss=0.2787, acc=0.8906
[03.15 16:01:15] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.17) training:  17%|█████                         | 391/2344 [01:01<01:27, 22.26x64b/s] | st=391, ep=0.17, loss=0.2506, acc=0.8906
[03.15 16:01:19] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.20) training:  20%|██████                        | 469/2344 [01:05<01:24, 22.24x64b/s] | st=469, ep=0.20, loss=0.1936, acc=0.9062
[03.15 16:01:36] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.20) checking:  33%|██████▋             | 261/782 [00:17<00:06, 79.95x64b/s]
[03.15 16:01:39] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.20) checking:  67%|█████████████▎      | 522/782 [00:20<00:03, 84.43x64b/s]
[03.15 16:01:43] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.20) checking: 100%|████████████████████| 782/782 [00:23<00:00, 79.84x64b/s] | st=469, ep=0.20, val_loss=0.2774, val_acc=0.8858
[03.15 16:01:47] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:01:51] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.23) training:  23%|███████                       | 547/2344 [01:37<01:24, 21.26x64b/s] | st=547, ep=0.23, loss=0.1921, acc=0.9219
[03.15 16:01:54] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.27) training:  27%|████████                      | 626/2344 [01:40<01:18, 21.89x64b/s] | st=626, ep=0.27, loss=0.2629, acc=0.9062
[03.15 16:01:58] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.30) training:  30%|█████████                     | 704/2344 [01:44<01:14, 22.15x64b/s] | st=704, ep=0.30, loss=0.3463, acc=0.8594
[03.15 16:02:14] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.30) checking:  33%|██████▋             | 261/782 [00:16<00:06, 75.76x64b/s]
[03.15 16:02:17] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.30) checking:  67%|█████████████▎      | 522/782 [00:19<00:03, 69.65x64b/s]
[03.15 16:02:21] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.30) checking: 100%|████████████████████| 782/782 [00:23<00:00, 72.25x64b/s] | st=704, ep=0.30, val_loss=0.2681, val_acc=0.8906
[03.15 16:02:24] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:02:28] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.33) training:  33%|██████████                    | 782/2344 [02:14<01:34, 16.60x64b/s] | st=782, ep=0.33, loss=0.1753, acc=0.9531
[03.15 16:02:31] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.37) training:  37%|███████████                   | 860/2344 [02:17<01:06, 22.18x64b/s] | st=860, ep=0.37, loss=0.3239, acc=0.8438
[03.15 16:02:35] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.40) training:  40%|████████████                  | 938/2344 [02:21<01:03, 22.17x64b/s] | st=938, ep=0.40, loss=0.3151, acc=0.8438
[03.15 16:02:52] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.40) checking:  33%|██████▋             | 261/782 [00:17<00:09, 55.67x64b/s]
[03.15 16:02:55] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.40) checking:  67%|█████████████▎      | 522/782 [00:20<00:04, 61.79x64b/s]
[03.15 16:02:59] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.40) checking: 100%|████████████████████| 782/782 [00:24<00:00, 81.15x64b/s] | st=938, ep=0.40, val_loss=0.2678, val_acc=0.8930
[03.15 16:03:03] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:03:06] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.43) training:  43%|█████████████                 | 1016/2344 [02:52<01:01, 21.76x64b/s] | st=1016, ep=0.43, loss=0.3911, acc=0.8281
[03.15 16:03:10] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.47) training:  47%|██████████████                | 1094/2344 [02:56<00:56, 22.23x64b/s] | st=1094, ep=0.47, loss=0.1603, acc=0.9375
[03.15 16:03:14] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.50) training:  50%|███████████████               | 1172/2344 [03:00<00:53, 21.91x64b/s] | st=1172, ep=0.50, loss=0.2147, acc=0.8906
[03.15 16:03:29] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.50) checking:  33%|██████▋             | 261/782 [00:15<00:08, 62.97x64b/s]
[03.15 16:03:32] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.50) checking:  67%|█████████████▎      | 522/782 [00:18<00:03, 68.48x64b/s]
[03.15 16:03:35] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.50) checking: 100%|████████████████████| 782/782 [00:21<00:00, 80.45x64b/s] | st=1172, ep=0.50, val_loss=0.2498, val_acc=0.8986
[03.15 16:03:38] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:03:42] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.53) training:  53%|████████████████              | 1251/2344 [03:28<00:50, 21.75x64b/s] | st=1251, ep=0.53, loss=0.1816, acc=0.9219
[03.15 16:03:46] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.57) training:  57%|█████████████████             | 1329/2344 [03:32<00:45, 22.09x64b/s] | st=1329, ep=0.57, loss=0.1670, acc=0.9531
[03.15 16:03:49] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.60) training:  60%|██████████████████            | 1407/2344 [03:35<00:42, 22.18x64b/s] | st=1407, ep=0.60, loss=0.3511, acc=0.8750
[03.15 16:04:07] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.60) checking:  33%|██████▋             | 261/782 [00:17<00:07, 71.71x64b/s]
[03.15 16:04:11] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.60) checking:  67%|█████████████▎      | 522/782 [00:21<00:03, 65.31x64b/s]
[03.15 16:04:14] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.60) checking: 100%|████████████████████| 782/782 [00:24<00:00, 82.61x64b/s] | st=1407, ep=0.60, val_loss=0.2561, val_acc=0.8942
[03.15 16:04:19] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:04:23] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.63) training:  63%|███████████████████           | 1485/2344 [04:09<00:39, 22.00x64b/s] | st=1485, ep=0.63, loss=0.2591, acc=0.8906
[03.15 16:04:27] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.67) training:  67%|████████████████████          | 1563/2344 [04:13<00:36, 21.27x64b/s] | st=1563, ep=0.67, loss=0.2869, acc=0.8438
[03.15 16:04:30] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.70) training:  70%|█████████████████████         | 1641/2344 [04:16<00:31, 22.38x64b/s] | st=1641, ep=0.70, loss=0.3116, acc=0.8750
[03.15 16:04:47] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.70) checking:  33%|██████▋             | 261/782 [00:16<00:06, 75.33x64b/s]
[03.15 16:04:50] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.70) checking:  67%|█████████████▎      | 522/782 [00:19<00:03, 67.34x64b/s]
[03.15 16:04:53] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.70) checking: 100%|████████████████████| 782/782 [00:23<00:00, 81.91x64b/s] | st=1641, ep=0.70, val_loss=0.2485, val_acc=0.9008
[03.15 16:04:57] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:05:00] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.73) training:  73%|██████████████████████        | 1719/2344 [04:46<00:28, 22.01x64b/s] | st=1719, ep=0.73, loss=0.1420, acc=0.9219
[03.15 16:05:04] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.77) training:  77%|███████████████████████       | 1798/2344 [04:50<00:24, 22.27x64b/s] | st=1798, ep=0.77, loss=0.3654, acc=0.8438
[03.15 16:05:08] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.80) training:  80%|████████████████████████      | 1876/2344 [04:54<00:21, 22.17x64b/s] | st=1876, ep=0.80, loss=0.2740, acc=0.8906
[03.15 16:05:26] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.80) checking:  33%|██████▋             | 261/782 [00:18<00:07, 74.19x64b/s]
[03.15 16:05:29] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.80) checking:  67%|█████████████▎      | 522/782 [00:21<00:03, 73.11x64b/s]
[03.15 16:05:33] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.80) checking: 100%|████████████████████| 782/782 [00:24<00:00, 79.71x64b/s] | st=1876, ep=0.80, val_loss=0.2529, val_acc=0.8961
[03.15 16:05:36] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:05:40] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.83) training:  83%|█████████████████████████     | 1954/2344 [05:26<00:17, 22.03x64b/s] | st=1954, ep=0.83, loss=0.3165, acc=0.8750
[03.15 16:05:43] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.87) training:  87%|██████████████████████████    | 2032/2344 [05:29<00:14, 22.15x64b/s] | st=2032, ep=0.87, loss=0.2668, acc=0.8906
[03.15 16:05:47] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.90) training:  90%|███████████████████████████   | 2110/2344 [05:33<00:10, 22.27x64b/s] | st=2110, ep=0.90, loss=0.3492, acc=0.8594
[03.15 16:06:03] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.90) checking:  33%|██████▋             | 261/782 [00:16<00:08, 65.10x64b/s]
[03.15 16:06:07] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.90) checking:  67%|█████████████▎      | 522/782 [00:19<00:03, 74.99x64b/s]
[03.15 16:06:10] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.90) checking: 100%|████████████████████| 782/782 [00:23<00:00, 77.95x64b/s] | st=2110, ep=0.90, val_loss=0.2540, val_acc=0.9017
[03.15 16:06:13] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:06:17] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.93) training:  93%|████████████████████████████  | 2188/2344 [06:03<00:07, 21.99x64b/s] | st=2188, ep=0.93, loss=0.1242, acc=0.9531
[03.15 16:06:20] ┇ INFO     ┇                                 __main__ ┇ (Ep 0.97) training:  97%|█████████████████████████████ | 2266/2344 [06:06<00:03, 22.19x64b/s] | st=2266, ep=0.97, loss=0.2506, acc=0.9062
[03.15 16:06:24] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.00) training: 100%|██████████████████████████████| 2344/2344 [06:10<00:00, 22.21x64b/s] | st=2344, ep=1.00, loss=0.3118, acc=0.8125
[03.15 16:06:42] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.00) checking:  33%|██████▋             | 261/782 [00:18<00:07, 67.34x64b/s]
[03.15 16:06:46] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.00) checking:  67%|█████████████▎      | 522/782 [00:21<00:03, 72.97x64b/s]
[03.15 16:06:49] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.00) checking: 100%|████████████████████| 782/782 [00:24<00:00, 83.11x64b/s] | st=2344, ep=1.00, val_loss=0.2428, val_acc=0.9027
[03.15 16:06:53] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:06:54] ┇ INFO     ┇                                 __main__ ┇ === [after-epoch] =======================================================================================================================
[03.15 16:07:12] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.03) training:   3%|█                             | 79/2344 [00:18<01:42, 22.04x64b/s] | st=2423, ep=1.03, loss=0.3071, acc=0.8906
[03.15 16:07:16] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.07) training:   7%|██                            | 157/2344 [00:22<01:42, 21.44x64b/s] | st=2501, ep=1.07, loss=0.1110, acc=0.9688
[03.15 16:07:20] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.10) training:  10%|███                           | 235/2344 [00:25<01:56, 18.11x64b/s] | st=2579, ep=1.10, loss=0.1610, acc=0.9375
[03.15 16:07:34] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.10) checking:  33%|██████▋             | 261/782 [00:14<00:07, 73.88x64b/s]
[03.15 16:07:38] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.10) checking:  67%|█████████████▎      | 522/782 [00:18<00:03, 75.00x64b/s]
[03.15 16:07:41] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.10) checking: 100%|████████████████████| 782/782 [00:21<00:00, 83.71x64b/s] | st=2579, ep=1.10, val_loss=0.2385, val_acc=0.9016
[03.15 16:07:45] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:07:49] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.13) training:  13%|████                          | 313/2344 [00:54<01:33, 21.77x64b/s] | st=2657, ep=1.13, loss=0.1282, acc=0.9531
[03.15 16:07:52] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.17) training:  17%|█████                         | 391/2344 [00:58<01:28, 22.08x64b/s] | st=2735, ep=1.17, loss=0.3168, acc=0.8906
[03.15 16:07:56] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.20) training:  20%|██████                        | 469/2344 [01:01<01:24, 22.22x64b/s] | st=2813, ep=1.20, loss=0.2092, acc=0.9375
[03.15 16:08:13] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.20) checking:  33%|██████▋             | 261/782 [00:16<00:07, 73.15x64b/s]
[03.15 16:08:16] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.20) checking:  67%|█████████████▎      | 522/782 [00:20<00:03, 79.94x64b/s]
[03.15 16:08:19] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.20) checking: 100%|████████████████████| 782/782 [00:23<00:00, 85.31x64b/s] | st=2813, ep=1.20, val_loss=0.2629, val_acc=0.9024
[03.15 16:08:23] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:08:26] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.23) training:  23%|███████                       | 547/2344 [01:32<01:22, 21.67x64b/s] | st=2891, ep=1.23, loss=0.4746, acc=0.8438
[03.15 16:08:30] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.27) training:  27%|████████                      | 626/2344 [01:36<01:22, 20.95x64b/s] | st=2970, ep=1.27, loss=0.2421, acc=0.9375
[03.15 16:08:34] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.30) training:  30%|█████████                     | 704/2344 [01:39<01:14, 22.10x64b/s] | st=3048, ep=1.30, loss=0.2544, acc=0.9219
[03.15 16:08:49] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.30) checking:  33%|██████▋             | 261/782 [00:15<00:06, 76.74x64b/s]
[03.15 16:08:52] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.30) checking:  67%|█████████████▎      | 522/782 [00:18<00:03, 84.74x64b/s]
[03.15 16:08:55] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.30) checking: 100%|████████████████████| 782/782 [00:21<00:00, 86.18x64b/s] | st=3048, ep=1.30, val_loss=0.2481, val_acc=0.9011
[03.15 16:08:56] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:09:00] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.33) training:  33%|██████████                    | 782/2344 [02:05<01:16, 20.41x64b/s] | st=3126, ep=1.33, loss=0.3482, acc=0.8906
[03.15 16:09:03] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.37) training:  37%|███████████                   | 860/2344 [02:09<01:06, 22.17x64b/s] | st=3204, ep=1.37, loss=0.2270, acc=0.9375
[03.15 16:09:07] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.40) training:  40%|████████████                  | 938/2344 [02:13<01:04, 21.71x64b/s] | st=3282, ep=1.40, loss=0.1586, acc=0.9219
[03.15 16:09:22] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.40) checking:  33%|██████▋             | 261/782 [00:15<00:06, 83.59x64b/s]
[03.15 16:09:26] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.40) checking:  67%|█████████████▎      | 522/782 [00:18<00:03, 86.02x64b/s]
[03.15 16:09:29] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.40) checking: 100%|████████████████████| 782/782 [00:22<00:00, 86.38x64b/s] | st=3282, ep=1.40, val_loss=0.2377, val_acc=0.9072
[03.15 16:09:32] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:09:36] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.43) training:  43%|█████████████                 | 1016/2344 [02:41<01:02, 21.27x64b/s] | st=3360, ep=1.43, loss=0.2307, acc=0.8906
[03.15 16:09:39] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.47) training:  47%|██████████████                | 1094/2344 [02:45<00:56, 22.24x64b/s] | st=3438, ep=1.47, loss=0.2995, acc=0.8750
[03.15 16:09:43] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.50) training:  50%|███████████████               | 1172/2344 [02:48<00:52, 22.20x64b/s] | st=3516, ep=1.50, loss=0.2696, acc=0.8750
[03.15 16:09:58] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.50) checking:  33%|██████▋             | 261/782 [00:14<00:06, 83.45x64b/s]
[03.15 16:10:01] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.50) checking:  67%|█████████████▎      | 522/782 [00:18<00:03, 82.04x64b/s]
[03.15 16:10:04] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.50) checking: 100%|████████████████████| 782/782 [00:21<00:00, 85.69x64b/s] | st=3516, ep=1.50, val_loss=0.2649, val_acc=0.8898
[03.15 16:10:05] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:10:09] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.53) training:  53%|████████████████              | 1251/2344 [03:14<00:49, 22.16x64b/s] | st=3595, ep=1.53, loss=0.2736, acc=0.9062
[03.15 16:10:12] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.57) training:  57%|█████████████████             | 1329/2344 [03:18<00:47, 21.59x64b/s] | st=3673, ep=1.57, loss=0.1105, acc=0.9375
[03.15 16:10:16] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.60) training:  60%|██████████████████            | 1407/2344 [03:22<00:42, 21.96x64b/s] | st=3751, ep=1.60, loss=0.1479, acc=0.9062
[03.15 16:10:31] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.60) checking:  33%|██████▋             | 261/782 [00:15<00:06, 79.26x64b/s]
[03.15 16:10:34] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.60) checking:  67%|█████████████▎      | 522/782 [00:18<00:02, 87.03x64b/s]
[03.15 16:10:37] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.60) checking: 100%|████████████████████| 782/782 [00:21<00:00, 86.38x64b/s] | st=3751, ep=1.60, val_loss=0.2431, val_acc=0.9064
[03.15 16:10:40] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:10:44] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.63) training:  63%|███████████████████           | 1485/2344 [03:50<00:39, 21.72x64b/s] | st=3829, ep=1.63, loss=0.1887, acc=0.9062
[03.15 16:10:48] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.67) training:  67%|████████████████████          | 1563/2344 [03:53<00:36, 21.67x64b/s] | st=3907, ep=1.67, loss=0.0899, acc=0.9531
[03.15 16:10:51] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.70) training:  70%|█████████████████████         | 1641/2344 [03:57<00:39, 17.86x64b/s] | st=3985, ep=1.70, loss=0.0796, acc=0.9844
[03.15 16:11:07] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.70) checking:  33%|██████▋             | 261/782 [00:15<00:06, 84.15x64b/s]
[03.15 16:11:10] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.70) checking:  67%|█████████████▎      | 522/782 [00:18<00:03, 79.40x64b/s]
[03.15 16:11:13] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.70) checking: 100%|████████████████████| 782/782 [00:21<00:00, 87.10x64b/s] | st=3985, ep=1.70, val_loss=0.2362, val_acc=0.9045
[03.15 16:11:16] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:11:20] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.73) training:  73%|██████████████████████        | 1719/2344 [04:25<00:28, 22.03x64b/s] | st=4063, ep=1.73, loss=0.2004, acc=0.8906
[03.15 16:11:23] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.77) training:  77%|███████████████████████       | 1798/2344 [04:29<00:24, 22.02x64b/s] | st=4142, ep=1.77, loss=0.1987, acc=0.8906
[03.15 16:11:27] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.80) training:  80%|████████████████████████      | 1876/2344 [04:33<00:21, 22.21x64b/s] | st=4220, ep=1.80, loss=0.3055, acc=0.8750
[03.15 16:11:43] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.80) checking:  33%|██████▋             | 261/782 [00:16<00:07, 67.78x64b/s]
[03.15 16:11:47] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.80) checking:  67%|█████████████▎      | 522/782 [00:19<00:03, 71.63x64b/s]
[03.15 16:11:50] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.80) checking: 100%|████████████████████| 782/782 [00:22<00:00, 84.22x64b/s] | st=4220, ep=1.80, val_loss=0.2475, val_acc=0.9045
[03.15 16:11:54] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:11:57] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.83) training:  83%|█████████████████████████     | 1954/2344 [05:03<00:17, 21.93x64b/s] | st=4298, ep=1.83, loss=0.1992, acc=0.9219
[03.15 16:12:01] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.87) training:  87%|██████████████████████████    | 2032/2344 [05:06<00:15, 20.36x64b/s] | st=4376, ep=1.87, loss=0.2611, acc=0.8906
[03.15 16:12:04] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.90) training:  90%|███████████████████████████   | 2110/2344 [05:10<00:10, 22.23x64b/s] | st=4454, ep=1.90, loss=0.2630, acc=0.9219
[03.15 16:12:22] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.90) checking:  33%|██████▋             | 261/782 [00:17<00:06, 83.61x64b/s]
[03.15 16:12:25] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.90) checking:  67%|█████████████▎      | 522/782 [00:21<00:02, 86.75x64b/s]
[03.15 16:12:29] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.90) checking: 100%|████████████████████| 782/782 [00:24<00:00, 86.51x64b/s] | st=4454, ep=1.90, val_loss=0.2469, val_acc=0.9061
[03.15 16:12:32] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:12:36] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.93) training:  93%|████████████████████████████  | 2188/2344 [05:41<00:07, 21.83x64b/s] | st=4532, ep=1.93, loss=0.2008, acc=0.9219
[03.15 16:12:39] ┇ INFO     ┇                                 __main__ ┇ (Ep 1.97) training:  97%|█████████████████████████████ | 2266/2344 [05:45<00:03, 22.06x64b/s] | st=4610, ep=1.97, loss=0.4835, acc=0.7969
[03.15 16:12:43] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.00) training: 100%|██████████████████████████████| 2344/2344 [05:49<00:00, 22.88x64b/s] | st=4688, ep=2.00, loss=0.3925, acc=0.7917
[03.15 16:13:00] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.00) checking:  33%|██████▋             | 261/782 [00:16<00:07, 71.73x64b/s]
[03.15 16:13:03] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.00) checking:  67%|█████████████▎      | 522/782 [00:19<00:03, 74.12x64b/s]
[03.15 16:13:06] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.00) checking: 100%|████████████████████| 782/782 [00:23<00:00, 77.15x64b/s] | st=4688, ep=2.00, val_loss=0.2393, val_acc=0.9062
[03.15 16:13:09] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:13:10] ┇ INFO     ┇                                 __main__ ┇ === [after-epoch] =======================================================================================================================
[03.15 16:13:28] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.03) training:   3%|█                             | 79/2344 [00:17<01:41, 22.31x64b/s] | st=4767, ep=2.03, loss=0.0890, acc=0.9688
[03.15 16:13:31] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.07) training:   7%|██                            | 157/2344 [00:21<01:38, 22.28x64b/s] | st=4845, ep=2.07, loss=0.1415, acc=0.9219
[03.15 16:13:35] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.10) training:  10%|███                           | 235/2344 [00:24<01:57, 17.94x64b/s] | st=4923, ep=2.10, loss=0.0691, acc=0.9844
[03.15 16:13:51] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.10) checking:  33%|██████▋             | 261/782 [00:15<00:06, 86.45x64b/s]
[03.15 16:13:54] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.10) checking:  67%|█████████████▎      | 522/782 [00:18<00:02, 86.82x64b/s]
[03.15 16:13:57] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.10) checking: 100%|████████████████████| 782/782 [00:21<00:00, 86.71x64b/s] | st=4923, ep=2.10, val_loss=0.2742, val_acc=0.9019
[03.15 16:13:58] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:14:02] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.13) training:  13%|████                          | 313/2344 [00:51<01:36, 21.05x64b/s] | st=5001, ep=2.13, loss=0.1011, acc=0.9688
[03.15 16:14:05] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.17) training:  17%|█████                         | 391/2344 [00:55<01:28, 22.09x64b/s] | st=5079, ep=2.17, loss=0.1280, acc=0.9375
[03.15 16:14:09] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.20) training:  20%|██████                        | 469/2344 [00:58<01:25, 21.96x64b/s] | st=5157, ep=2.20, loss=0.3403, acc=0.8438
[03.15 16:14:25] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.20) checking:  33%|██████▋             | 261/782 [00:16<00:09, 54.74x64b/s]
[03.15 16:14:28] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.20) checking:  67%|█████████████▎      | 522/782 [00:19<00:03, 80.01x64b/s]
[03.15 16:14:32] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.20) checking: 100%|████████████████████| 782/782 [00:22<00:00, 81.93x64b/s] | st=5157, ep=2.20, val_loss=0.2818, val_acc=0.9034
[03.15 16:14:32] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:14:36] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.23) training:  23%|███████                       | 547/2344 [01:25<01:22, 21.82x64b/s] | st=5235, ep=2.23, loss=0.1922, acc=0.9375
[03.15 16:14:40] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.27) training:  27%|████████                      | 626/2344 [01:29<01:17, 22.13x64b/s] | st=5314, ep=2.27, loss=0.1664, acc=0.9219
[03.15 16:14:43] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.30) training:  30%|█████████                     | 704/2344 [01:33<01:13, 22.18x64b/s] | st=5392, ep=2.30, loss=0.1686, acc=0.9062
[03.15 16:15:02] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.30) checking:  33%|██████▋             | 261/782 [00:18<00:06, 79.72x64b/s]
[03.15 16:15:05] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.30) checking:  67%|█████████████▎      | 522/782 [00:22<00:03, 78.23x64b/s]
[03.15 16:15:09] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.30) checking: 100%|████████████████████| 782/782 [00:25<00:00, 85.40x64b/s] | st=5392, ep=2.30, val_loss=0.2971, val_acc=0.9028
[03.15 16:15:10] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:15:13] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.33) training:  33%|██████████                    | 782/2344 [02:03<01:20, 19.50x64b/s] | st=5470, ep=2.33, loss=0.0345, acc=0.9844
[03.15 16:15:17] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.37) training:  37%|███████████                   | 860/2344 [02:06<01:07, 22.00x64b/s] | st=5548, ep=2.37, loss=0.1137, acc=0.9531
[03.15 16:15:21] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.40) training:  40%|████████████                  | 938/2344 [02:10<01:03, 22.18x64b/s] | st=5626, ep=2.40, loss=0.2300, acc=0.9219
[03.15 16:15:37] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.40) checking:  33%|██████▋             | 261/782 [00:16<00:06, 78.51x64b/s]
[03.15 16:15:40] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.40) checking:  67%|█████████████▎      | 522/782 [00:19<00:03, 85.11x64b/s]
[03.15 16:15:43] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.40) checking: 100%|████████████████████| 782/782 [00:22<00:00, 86.31x64b/s] | st=5626, ep=2.40, val_loss=0.2541, val_acc=0.9045
[03.15 16:15:44] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:15:48] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.43) training:  43%|█████████████                 | 1016/2344 [02:37<01:03, 21.01x64b/s] | st=5704, ep=2.43, loss=0.3480, acc=0.8438
[03.15 16:15:51] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.47) training:  47%|██████████████                | 1094/2344 [02:41<00:56, 22.05x64b/s] | st=5782, ep=2.47, loss=0.1724, acc=0.9375
[03.15 16:15:55] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.50) training:  50%|███████████████               | 1172/2344 [02:44<00:52, 22.15x64b/s] | st=5860, ep=2.50, loss=0.1872, acc=0.9062
[03.15 16:16:10] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.50) checking:  33%|██████▋             | 261/782 [00:15<00:06, 81.28x64b/s]
[03.15 16:16:14] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.50) checking:  67%|█████████████▎      | 522/782 [00:18<00:03, 83.57x64b/s]
[03.15 16:16:17] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.50) checking: 100%|████████████████████| 782/782 [00:22<00:00, 86.62x64b/s] | st=5860, ep=2.50, val_loss=0.2799, val_acc=0.9021
[03.15 16:16:17] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:16:21] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.53) training:  53%|████████████████              | 1251/2344 [03:11<00:51, 21.23x64b/s] | st=5939, ep=2.53, loss=0.1297, acc=0.9531
[03.15 16:16:25] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.57) training:  57%|█████████████████             | 1329/2344 [03:14<00:48, 21.08x64b/s] | st=6017, ep=2.57, loss=0.1361, acc=0.9375
[03.15 16:16:28] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.60) training:  60%|██████████████████            | 1407/2344 [03:18<00:42, 22.00x64b/s] | st=6095, ep=2.60, loss=0.2516, acc=0.8906
[03.15 16:16:44] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.60) checking:  33%|██████▋             | 261/782 [00:15<00:07, 65.86x64b/s]
[03.15 16:16:48] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.60) checking:  67%|█████████████▎      | 522/782 [00:19<00:03, 69.61x64b/s]
[03.15 16:16:51] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.60) checking: 100%|████████████████████| 782/782 [00:22<00:00, 79.44x64b/s] | st=6095, ep=2.60, val_loss=0.2676, val_acc=0.9064
[03.15 16:16:54] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:16:57] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.63) training:  63%|███████████████████           | 1485/2344 [03:47<00:39, 21.79x64b/s] | st=6173, ep=2.63, loss=0.0699, acc=0.9844
[03.15 16:17:01] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.67) training:  67%|████████████████████          | 1563/2344 [03:50<00:36, 21.46x64b/s] | st=6251, ep=2.67, loss=0.2114, acc=0.9062
[03.15 16:17:05] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.70) training:  70%|█████████████████████         | 1641/2344 [03:54<00:32, 21.72x64b/s] | st=6329, ep=2.70, loss=0.2186, acc=0.9062
[03.15 16:17:23] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.70) checking:  33%|██████▋             | 261/782 [00:18<00:06, 84.57x64b/s]
[03.15 16:17:26] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.70) checking:  67%|█████████████▎      | 522/782 [00:21<00:03, 84.19x64b/s]
[03.15 16:17:30] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.70) checking: 100%|████████████████████| 782/782 [00:25<00:00, 86.60x64b/s] | st=6329, ep=2.70, val_loss=0.2768, val_acc=0.9000
[03.15 16:17:30] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:17:34] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.73) training:  73%|██████████████████████        | 1719/2344 [04:24<00:28, 21.96x64b/s] | st=6407, ep=2.73, loss=0.2471, acc=0.9219
[03.15 16:17:38] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.77) training:  77%|███████████████████████       | 1798/2344 [04:27<00:26, 20.89x64b/s] | st=6486, ep=2.77, loss=0.1637, acc=0.9219
[03.15 16:17:42] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.80) training:  80%|████████████████████████      | 1876/2344 [04:31<00:20, 22.37x64b/s] | st=6564, ep=2.80, loss=0.3577, acc=0.8750
[03.15 16:17:58] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.80) checking:  33%|██████▋             | 261/782 [00:16<00:07, 72.14x64b/s]
[03.15 16:18:02] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.80) checking:  67%|█████████████▎      | 522/782 [00:20<00:03, 75.24x64b/s]
[03.15 16:18:05] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.80) checking: 100%|████████████████████| 782/782 [00:23<00:00, 79.55x64b/s] | st=6564, ep=2.80, val_loss=0.2521, val_acc=0.9066
[03.15 16:18:08] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:18:11] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.83) training:  83%|█████████████████████████     | 1954/2344 [05:01<00:17, 21.99x64b/s] | st=6642, ep=2.83, loss=0.1031, acc=0.9531
[03.15 16:18:15] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.87) training:  87%|██████████████████████████    | 2032/2344 [05:04<00:16, 19.34x64b/s] | st=6720, ep=2.87, loss=0.1237, acc=0.9531
[03.15 16:18:18] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.90) training:  90%|███████████████████████████   | 2110/2344 [05:08<00:10, 22.05x64b/s] | st=6798, ep=2.90, loss=0.1272, acc=0.9688
[03.15 16:18:36] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.90) checking:  33%|██████▋             | 261/782 [00:17<00:07, 74.19x64b/s]
[03.15 16:18:39] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.90) checking:  67%|█████████████▎      | 522/782 [00:20<00:03, 73.73x64b/s]
[03.15 16:18:43] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.90) checking: 100%|████████████████████| 782/782 [00:24<00:00, 79.32x64b/s] | st=6798, ep=2.90, val_loss=0.2840, val_acc=0.9017
[03.15 16:18:44] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:18:47] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.93) training:  93%|████████████████████████████  | 2188/2344 [05:37<00:07, 22.13x64b/s] | st=6876, ep=2.93, loss=0.2054, acc=0.9375
[03.15 16:18:51] ┇ INFO     ┇                                 __main__ ┇ (Ep 2.97) training:  97%|█████████████████████████████ | 2266/2344 [05:40<00:03, 22.35x64b/s] | st=6954, ep=2.97, loss=0.2535, acc=0.8750
[03.15 16:18:54] ┇ INFO     ┇                                 __main__ ┇ (Ep 3.00) training: 100%|██████████████████████████████| 2344/2344 [05:44<00:00, 21.82x64b/s] | st=7032, ep=3.00, loss=0.0601, acc=0.9792
[03.15 16:19:10] ┇ INFO     ┇                                 __main__ ┇ (Ep 3.00) checking:  33%|██████▋             | 261/782 [00:15<00:08, 62.08x64b/s]
[03.15 16:19:13] ┇ INFO     ┇                                 __main__ ┇ (Ep 3.00) checking:  67%|█████████████▎      | 522/782 [00:18<00:03, 70.37x64b/s]
[03.15 16:19:17] ┇ INFO     ┇                                 __main__ ┇ (Ep 3.00) checking: 100%|████████████████████| 782/782 [00:22<00:00, 79.91x64b/s] | st=7032, ep=3.00, val_loss=0.2661, val_acc=0.9030
[03.15 16:19:17] ┇ INFO     ┇                                 __main__ ┇ --- [after-check] -----------------------------------------------------------------------------------------------------------------------
[03.15 16:19:19] ┇ INFO     ┇                                 __main__ ┇ === [after-epoch] =======================================================================================================================
[03.15 16:19:19] ┇ INFO     ┇                                 __main__ ┇ (Ep 3.00) testing /raid/chrisjihee/proj/DeepKNLP-24.01/finetuning/nsmc/train=KPF-BERT/0315.155950/ep=1.4, loss=0.2377, acc=0.9072.ckpt:
ckpt_saver.best_model_path=/raid/chrisjihee/proj/DeepKNLP-24.01/finetuning/nsmc/train=KPF-BERT/0315.155950/ep=1.4, loss=0.2377, acc=0.9072.ckpt
model.args(1)=TrainerArguments(env=ProjectEnv(project='DeepKNLP', job_name='KPF-BERT', hostname='dgx-a100', hostaddr='129.254.23.12', python_path=PosixPath('/raid/chrisjihee/miniforge3/envs/DeepKNLP-24.01/bin/python'), current_dir=PosixPath('/raid/chrisjihee/proj/DeepKNLP-24.01'), current_file=PosixPath('/raid/chrisjihee/proj/DeepKNLP-24.01/1-doc-cls-fab.py'), working_dir=PosixPath('/raid/chrisjihee/proj/DeepKNLP-24.01'), command_args=[], num_ip_addrs=1, max_workers=1, output_home=PosixPath('/raid/chrisjihee/proj/DeepKNLP-24.01/finetuning/nsmc/train=KPF-BERT/0315.155950'), logging_file=None, argument_file=PosixPath('train-arguments-0315.155950-train.json'), debugging=False, msg_level=20, msg_format='%(asctime)s ┇ %(levelname)-8s ┇ %(name)40s ┇ %(message)s', date_format='[%m.%d %H:%M:%S]', time_stamp='0315.155950'), prog=ProgressChecker(result={}, tb_logger=<lightning.fabric.loggers.tensorboard.TensorBoardLogger object at 0x7f51267da7d0>, csv_logger=<lightning.fabric.loggers.csv_logs.CSVLogger object at 0x7f5074379a50>, world_size=1, node_rank=0, local_rank=0, global_rank=0, global_step=7032, global_epoch=3.0), data=DataOption(name='nsmc', home=PosixPath('/raid/chrisjihee/proj/DeepKNLP-24.01/data'), files=DataFiles(train='ratings_train.txt', valid='ratings_test.txt', test=None), caching=False, redownload=False, num_check=2, num_entity=None, num_relation=None), model=ModelOption(pretrained=PosixPath('pretrained/KPF-BERT'), finetuning=PosixPath('/raid/chrisjihee/proj/DeepKNLP-24.01/finetuning'), seq_len=64, config=None, name=None, src_max_length=512, train_tgt_max_length=512, eval_tgt_max_length=90, src_descrip_max_length=0, tgt_descrip_max_length=0, seq_dropout=0.1, decoder='beam_search', num_beams=40, num_beam_groups=1, diversity_penalty=0.0, use_prefix_search=False), hardware=HardwareOption(cpu_workers=256, train_batch=64, infer_batch=64, accelerator='gpu', precision='32-true', strategy='auto', devices=[1]), learning=LearningOption(random_seed=7, optimizer_cls='Adam', learning_rate=5e-05, saving_mode='max val_acc', num_saving=3, num_epochs=3, log_text=False, check_rate_on_training=0.1, print_rate_on_training=0.03333333333333333, print_rate_on_validate=0.3333333333333333, print_rate_on_evaluate=0.3333333333333333, print_step_on_training=-1, print_step_on_validate=-1, print_step_on_evaluate=-1, tag_format_on_training='st={step:d}, ep={epoch:.2f}, loss={loss:06.4f}, acc={acc:06.4f}', tag_format_on_validate='st={step:d}, ep={epoch:.2f}, val_loss={val_loss:06.4f}, val_acc={val_acc:06.4f}', tag_format_on_evaluate='st={step:d}, ep={epoch:.2f}, test_loss={test_loss:06.4f}, test_acc={test_acc:06.4f}', name_format_on_saving='ep={epoch:.1f}, loss={val_loss:06.4f}, acc={val_acc:06.4f}'))
type(ckpt_state)=<class 'dict'>
ckpt_state.keys()=dict_keys(['model', 'optimizer'])
model.args(2)=TrainerArguments(env=ProjectEnv(project='DeepKNLP', job_name='KPF-BERT', hostname='dgx-a100', hostaddr='129.254.23.12', python_path=PosixPath('/raid/chrisjihee/miniforge3/envs/DeepKNLP-24.01/bin/python'), current_dir=PosixPath('/raid/chrisjihee/proj/DeepKNLP-24.01'), current_file=PosixPath('/raid/chrisjihee/proj/DeepKNLP-24.01/1-doc-cls-fab.py'), working_dir=PosixPath('/raid/chrisjihee/proj/DeepKNLP-24.01'), command_args=[], num_ip_addrs=1, max_workers=1, output_home=PosixPath('/raid/chrisjihee/proj/DeepKNLP-24.01/finetuning/nsmc/train=KPF-BERT/0315.155950'), logging_file=None, argument_file=PosixPath('train-arguments-0315.155950-train.json'), debugging=False, msg_level=20, msg_format='%(asctime)s ┇ %(levelname)-8s ┇ %(name)40s ┇ %(message)s', date_format='[%m.%d %H:%M:%S]', time_stamp='0315.155950'), prog=ProgressChecker(result={}, tb_logger=<lightning.fabric.loggers.tensorboard.TensorBoardLogger object at 0x7f51267da7d0>, csv_logger=<lightning.fabric.loggers.csv_logs.CSVLogger object at 0x7f5074379a50>, world_size=1, node_rank=0, local_rank=0, global_rank=0, global_step=7032, global_epoch=3.0), data=DataOption(name='nsmc', home=PosixPath('/raid/chrisjihee/proj/DeepKNLP-24.01/data'), files=DataFiles(train='ratings_train.txt', valid='ratings_test.txt', test=None), caching=False, redownload=False, num_check=2, num_entity=None, num_relation=None), model=ModelOption(pretrained=PosixPath('pretrained/KPF-BERT'), finetuning=PosixPath('/raid/chrisjihee/proj/DeepKNLP-24.01/finetuning'), seq_len=64, config=None, name=None, src_max_length=512, train_tgt_max_length=512, eval_tgt_max_length=90, src_descrip_max_length=0, tgt_descrip_max_length=0, seq_dropout=0.1, decoder='beam_search', num_beams=40, num_beam_groups=1, diversity_penalty=0.0, use_prefix_search=False), hardware=HardwareOption(cpu_workers=256, train_batch=64, infer_batch=64, accelerator='gpu', precision='32-true', strategy='auto', devices=[1]), learning=LearningOption(random_seed=7, optimizer_cls='Adam', learning_rate=5e-05, saving_mode='max val_acc', num_saving=3, num_epochs=3, log_text=False, check_rate_on_training=0.1, print_rate_on_training=0.03333333333333333, print_rate_on_validate=0.3333333333333333, print_rate_on_evaluate=0.3333333333333333, print_step_on_training=-1, print_step_on_validate=-1, print_step_on_evaluate=-1, tag_format_on_training='st={step:d}, ep={epoch:.2f}, loss={loss:06.4f}, acc={acc:06.4f}', tag_format_on_validate='st={step:d}, ep={epoch:.2f}, val_loss={val_loss:06.4f}, val_acc={val_acc:06.4f}', tag_format_on_evaluate='st={step:d}, ep={epoch:.2f}, test_loss={test_loss:06.4f}, test_acc={test_acc:06.4f}', name_format_on_saving='ep={epoch:.1f}, loss={val_loss:06.4f}, acc={val_acc:06.4f}'))
[03.15 16:19:42] ┇ INFO     ┇                                 __main__ ┇ (Ep 3.00)  testing:  33%|██████▋             | 261/782 [00:22<00:06, 86.26x64b/s]
[03.15 16:19:46] ┇ INFO     ┇                                 __main__ ┇ (Ep 3.00)  testing:  67%|█████████████▎      | 522/782 [00:26<00:02, 86.67x64b/s]
[03.15 16:19:49] ┇ INFO     ┇                                 __main__ ┇ (Ep 3.00)  testing: 100%|████████████████████| 782/782 [00:29<00:00, 54.81x64b/s] | st=7032, ep=3.00, test_loss=0.2377, test_acc=0.9072
[03.15 16:19:50] ┇ INFO     ┇                                 __main__ ┇ --- [after-test] ------------------------------------------------------------------------------------------------------------------------
[03.15 16:19:50] ┇ INFO     ┇                                 __main__ ┇ === [after-train_loop] ==================================================================================================================
[03.15 16:19:50] ┇ INFO     ┇                           chrisbase.data ┇ =========================================================================================================================================
[03.15 16:19:50] ┇ INFO     ┇                           chrisbase.data ┇ [EXIT] python /raid/chrisjihee/proj/DeepKNLP-24.01/1-doc-cls-fab.py  ($=00:19:56.467)
[03.15 16:19:50] ┇ INFO     ┇                           chrisbase.data ┇ =========================================================================================================================================

Process finished with exit code 0
